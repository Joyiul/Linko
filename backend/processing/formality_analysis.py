import re
import os
import pandas as pd
from collections import Counter

class FormalityAnalyzer:
    def __init__(self):
        """Initialize formality analyzer with comprehensive patterns"""
        
        # Formal language indicators
        self.formal_patterns = {
            'academic_words': [
                'furthermore', 'consequently', 'nevertheless', 'notwithstanding', 'pursuant', 
                'aforementioned', 'subsequent', 'facilitate', 'demonstrate', 'establish',
                'implement', 'analyze', 'evaluate', 'synthesize', 'constitute', 'endeavor',
                'ascertain', 'utilize', 'commence', 'terminate', 'subsequent', 'preliminary',
                'comprehensive', 'substantial', 'significant', 'exemplify', 'illustrate'
            ],
            'formal_phrases': [
                'i would like to', 'i am writing to', 'i would be grateful', 'please find attached',
                'thank you for your consideration', 'i look forward to', 'yours sincerely',
                'yours faithfully', 'dear sir/madam', 'to whom it may concern', 'in accordance with',
                'with regard to', 'pursuant to', 'in compliance with', 'i am pleased to inform',
                'please be advised', 'we regret to inform', 'it has come to our attention'
            ],
            'formal_structures': [
                r'\bi am writing to\b', r'\bplease be advised\b', r'\bi would like to request\b',
                r'\bit is my understanding\b', r'\bi trust this finds you well\b',
                r'\bthank you for your time and consideration\b'
            ],
            'polite_requests': [
                'would you be so kind', 'if you would be so kind', 'i would appreciate',
                'could you please', 'would it be possible', 'i wonder if you might',
                'perhaps you could', 'if it is not too much trouble'
            ]
        }
        
        # Informal language indicators
        self.informal_patterns = {
            'contractions': [
                "won't", "can't", "don't", "doesn't", "didn't", "wasn't", "weren't", "haven't",
                "hasn't", "hadn't", "shouldn't", "wouldn't", "couldn't", "isn't", "aren't",
                "i'm", "you're", "we're", "they're", "it's", "that's", "what's", "who's",
                "i'll", "you'll", "we'll", "they'll", "i'd", "you'd", "we'd", "they'd",
                "i've", "you've", "we've", "they've"
            ],
            'casual_words': [
                'yeah', 'nah', 'yep', 'nope', 'ok', 'okay', 'cool', 'awesome', 'great',
                'nice', 'sweet', 'dude', 'guy', 'folks', 'stuff', 'things', 'kinda',
                'sorta', 'gonna', 'wanna', 'gotta', 'dunno', 'lemme', 'gimme'
            ],
            'informal_phrases': [
                'how are you doing', 'what\'s up', 'how\'s it going', 'see you later',
                'talk to you soon', 'catch you later', 'take care', 'no worries',
                'no problem', 'you bet', 'for sure', 'totally', 'absolutely'
            ],
            'filler_words': [
                'like', 'you know', 'i mean', 'basically', 'literally', 'actually',
                'honestly', 'seriously', 'obviously', 'definitely', 'probably'
            ]
        }
        
        # Very casual/slang indicators
        self.casual_patterns = {
            'slang_words': [
                'bro', 'sis', 'bestie', 'fam', 'squad', 'lit', 'fire', 'sick', 'dope',
                'epic', 'legit', 'sus', 'vibe', 'mood', 'flex', 'salty', 'savage',
                'periodt', 'lowkey', 'highkey', 'deadass', 'fr', 'ngl', 'tbh', 'imo',
                'lol', 'lmao', 'wtf', 'omg', 'brb', 'ttyl', 'dm', 'slide'
            ],
            'internet_slang': [
                'smh', 'fomo', 'yolo', 'tfw', 'mfw', 'irl', 'af', 'goat', 'stan',
                'ship', 'simp', 'karen', 'boomer', 'zoomer', 'cancelled', 'ghosted',
                'finsta', 'spam', 'story', 'post', 'dm', 'slide into dms'
            ],
            'intensifiers': [
                'hella', 'mad', 'crazy', 'insane', 'wild', 'nuts', 'bananas',
                'stupid good', 'dummy thicc', 'lowkey fire', 'no cap'
            ]
        }
        
        # Professional/business language
        self.professional_patterns = {
            'business_terms': [
                'synergy', 'leverage', 'optimize', 'streamline', 'paradigm', 'benchmark',
                'deliverable', 'stakeholder', 'roi', 'kpi', 'metrics', 'actionable',
                'scalable', 'bandwidth', 'circle back', 'touch base', 'reach out',
                'drill down', 'deep dive', 'best practice', 'win-win', 'game changer'
            ],
            'corporate_phrases': [
                'think outside the box', 'low hanging fruit', 'move the needle',
                'let\'s take this offline', 'i\'ll circle back', 'let\'s touch base',
                'we need to ideate', 'let\'s brainstorm', 'action items',
                'going forward', 'at the end of the day', 'it is what it is'
            ]
        }
        
        # Load additional datasets if available
        self._load_additional_patterns()
    
    def _load_additional_patterns(self):
        """Load additional formality patterns from datasets"""
        try:
            # Try to load Gen Z slang from existing dataset
            datasets_path = os.path.join(os.path.dirname(__file__), '..', 'Datasets')
            
            # Load Gen Z slang
            genz_path = os.path.join(datasets_path, 'genz_slang.csv')
            if os.path.exists(genz_path):
                genz_df = pd.read_csv(genz_path)
                if 'term' in genz_df.columns:
                    genz_terms = genz_df['term'].str.lower().tolist()
                    self.casual_patterns['slang_words'].extend(genz_terms[:50])  # Add top 50
            
            # Load general slang
            slang_path = os.path.join(datasets_path, 'slang.csv')
            if os.path.exists(slang_path):
                slang_df = pd.read_csv(slang_path)
                if 'slang' in slang_df.columns:
                    slang_terms = slang_df['slang'].str.lower().tolist()
                    self.casual_patterns['slang_words'].extend(slang_terms[:50])  # Add top 50
                    
        except Exception as e:
            print(f"Note: Could not load additional slang datasets: {e}")
    
    def analyze_formality(self, text):
        """
        Analyze the formality level of given text
        Returns detailed formality analysis
        """
        if not text or not text.strip():
            return {
                'formality_level': 'unknown',
                'confidence': 0.0,
                'details': {},
                'indicators': []
            }
        
        text_lower = text.lower()
        word_count = len(text.split())
        
        # Count different formality indicators
        formal_score = 0
        informal_score = 0
        casual_score = 0
        professional_score = 0
        
        indicators = {
            'formal': [],
            'informal': [],
            'casual': [],
            'professional': []
        }
        
        # Check formal patterns
        for word in self.formal_patterns['academic_words']:
            if word in text_lower:
                formal_score += 3
                indicators['formal'].append(f"Academic word: '{word}'")
        
        for phrase in self.formal_patterns['formal_phrases']:
            if phrase in text_lower:
                formal_score += 5
                indicators['formal'].append(f"Formal phrase: '{phrase}'")
        
        for pattern in self.formal_patterns['formal_structures']:
            if re.search(pattern, text_lower, re.IGNORECASE):
                formal_score += 4
                indicators['formal'].append(f"Formal structure detected")
        
        for phrase in self.formal_patterns['polite_requests']:
            if phrase in text_lower:
                formal_score += 3
                indicators['formal'].append(f"Polite request: '{phrase}'")
        
        # Check informal patterns
        for contraction in self.informal_patterns['contractions']:
            if contraction in text_lower:
                informal_score += 2
                indicators['informal'].append(f"Contraction: '{contraction}'")
        
        for word in self.informal_patterns['casual_words']:
            if word in text_lower:
                informal_score += 2
                indicators['informal'].append(f"Casual word: '{word}'")
        
        for phrase in self.informal_patterns['informal_phrases']:
            if phrase in text_lower:
                informal_score += 3
                indicators['informal'].append(f"Informal phrase: '{phrase}'")
        
        for filler in self.informal_patterns['filler_words']:
            count = len(re.findall(r'\b' + filler + r'\b', text_lower))
            if count > 0:
                informal_score += count * 1
                indicators['informal'].append(f"Filler word: '{filler}' ({count}x)")
        
        # Check casual/slang patterns
        for slang in self.casual_patterns['slang_words']:
            if slang in text_lower:
                casual_score += 3
                indicators['casual'].append(f"Slang: '{slang}'")
        
        for internet_slang in self.casual_patterns['internet_slang']:
            if internet_slang in text_lower:
                casual_score += 4
                indicators['casual'].append(f"Internet slang: '{internet_slang}'")
        
        for intensifier in self.casual_patterns['intensifiers']:
            if intensifier in text_lower:
                casual_score += 2
                indicators['casual'].append(f"Casual intensifier: '{intensifier}'")
        
        # Check professional patterns
        for term in self.professional_patterns['business_terms']:
            if term in text_lower:
                professional_score += 3
                indicators['professional'].append(f"Business term: '{term}'")
        
        for phrase in self.professional_patterns['corporate_phrases']:
            if phrase in text_lower:
                professional_score += 4
                indicators['professional'].append(f"Corporate phrase: '{phrase}'")
        
        # Additional indicators
        # Check sentence structure complexity
        sentences = re.split(r'[.!?]+', text)
        avg_sentence_length = sum(len(s.split()) for s in sentences if s.strip()) / max(len([s for s in sentences if s.strip()]), 1)
        
        if avg_sentence_length > 20:
            formal_score += 2
            indicators['formal'].append(f"Complex sentences (avg {avg_sentence_length:.1f} words)")
        elif avg_sentence_length < 8:
            casual_score += 1
            indicators['casual'].append(f"Short sentences (avg {avg_sentence_length:.1f} words)")
        
        # Check punctuation patterns
        exclamation_count = text.count('!')
        if exclamation_count > 2:
            casual_score += exclamation_count
            indicators['casual'].append(f"Multiple exclamations ({exclamation_count})")
        
        # Check capitalization patterns
        if text.isupper():
            casual_score += 3
            indicators['casual'].append("ALL CAPS usage")
        elif any(word.isupper() for word in text.split()):
            casual_score += 1
            indicators['casual'].append("Some words in caps")
        
        # Determine formality level
        scores = {
            'formal': formal_score,
            'professional': professional_score,
            'informal': informal_score,
            'casual': casual_score
        }
        
        max_score = max(scores.values())
        total_score = sum(scores.values())
        
        if max_score == 0:
            formality_level = 'neutral'
            confidence = 0.3
        else:
            formality_level = max(scores, key=scores.get)
            confidence = min(max_score / max(total_score, 1) * 1.2, 0.95)
        
        # Detailed breakdown
        details = {
            'scores': scores,
            'total_indicators': sum(len(indicators[key]) for key in indicators),
            'word_count': word_count,
            'avg_sentence_length': avg_sentence_length,
            'formality_distribution': {
                key: round(score / max(total_score, 1) * 100, 1) 
                for key, score in scores.items()
            }
        }
        
        return {
            'formality_level': formality_level,
            'confidence': confidence,
            'details': details,
            'indicators': indicators,
            'summary': self._generate_formality_summary(formality_level, confidence, indicators)
        }
    
    def _generate_formality_summary(self, level, confidence, indicators):
        """Generate a human-readable summary of formality analysis"""
        summaries = {
            'formal': "This text uses formal, academic language with complex sentence structures and polite expressions.",
            'professional': "This text uses business/corporate language with professional terminology and structured communication.",
            'informal': "This text uses conversational language with contractions and casual expressions.",
            'casual': "This text uses very casual language with slang, informal expressions, and relaxed tone.",
            'neutral': "This text maintains a neutral tone without strong formality indicators."
        }
        
        base_summary = summaries.get(level, "Formality level unclear.")
        
        # Add confidence level
        confidence_desc = ""
        if confidence >= 0.8:
            confidence_desc = " (High confidence)"
        elif confidence >= 0.6:
            confidence_desc = " (Moderate confidence)"
        else:
            confidence_desc = " (Low confidence)"
        
        # Add key indicators
        key_indicators = []
        for category, items in indicators.items():
            if items and len(items) > 0:
                key_indicators.append(f"{len(items)} {category} indicators")
        
        if key_indicators:
            indicator_summary = f" Found: {', '.join(key_indicators)}."
        else:
            indicator_summary = ""
        
        return base_summary + confidence_desc + indicator_summary

# Global instance for easy import
formality_analyzer = FormalityAnalyzer()

def analyze_formality(text):
    """Convenience function for formality analysis"""
    return formality_analyzer.analyze_formality(text)
